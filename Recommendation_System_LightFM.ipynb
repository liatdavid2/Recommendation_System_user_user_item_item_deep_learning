{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation System - LightFM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Understand and order data"
      ],
      "metadata": {
        "id": "ol-_uUq_92y2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2agZ0fTRXZrg",
        "outputId": "66e503c0-4d08-4a5f-e06b-214ef0c5ed49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LightFM is a Python implementation of a number of popular recommendation algorithms:\n",
        "\n",
        "It also makes it possible to incorporate both item and user metadata into the traditional matrix factorization algorithms. It represents each user and item as the sum of the latent representations of their features, thus allowing recommendations to generalise to new items (via item features) and to new users (via user features)."
      ],
      "metadata": {
        "id": "kfJwXWbXXzJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install lightFM, takes around 15 seconds\n",
        "!pip install lightfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jo-d6qvXyzj",
        "outputId": "0a868fa0-cd9b-4e9b-a854-c2696505d46e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705378 sha256=34fdd0aea5275ffad5e87a74b7c0f4223d41c56a3a1f9290cd762ff1f77eb510\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mObVypUdyFfz"
      },
      "source": [
        "The first step is to get the Movielens data. This is a classic small recommender dataset, consisting of around 950 users, 1700 movies, and 100,000 ratings. The ratings are on a scale from 1 to 5, but we’ll all treat them as implicit positive feedback in this example.\n",
        "\n",
        "Fortunately, this is one of the functions provided by LightFM itself."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our modules\n",
        "import numpy as np\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm import LightFM\n",
        "# Use one of LightFM's inbuild datasets, setting the minimum rating to return at over 4.0\n",
        "data = fetch_movielens(min_rating = 4.0)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZfkqo83XpIk",
        "outputId": "f964aebb-d6cc-43d2-a16c-884ad9a9376b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
              " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
              " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
              " \twith 5469 stored elements in COOrdinate format>,\n",
              " 'train': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
              " \twith 49906 stored elements in COOrdinate format>}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get our key and value from our dataset\n",
        "# By printing it, we see it's comprised of a data segments containing test, train, item_features, item_feature_labels & item_labels \n",
        "for key, value in data.items():\n",
        "    print(key, type(value), value.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozOCr5fYQ-Y",
        "outputId": "6b7d4b2d-7f72-4a5f-f6e1-1a43ae955e05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train <class 'scipy.sparse.coo.coo_matrix'> (943, 1682)\n",
            "test <class 'scipy.sparse.coo.coo_matrix'> (943, 1682)\n",
            "item_features <class 'scipy.sparse.csr.csr_matrix'> (1682, 1682)\n",
            "item_feature_labels <class 'numpy.ndarray'> (1682,)\n",
            "item_labels <class 'numpy.ndarray'> (1682,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What type of data are we working with? coo_matrix\n",
        "type(data['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VhCBwk4YZzl",
        "outputId": "4cf3e816-ddb8-4766-ca2a-c69241bdcaaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.coo.coo_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each row represents a user, and each column an item. \n",
        "# We use .tocsr() to view it as a Compressed Sparse Row format, it's an inbuilt function in the coo_matrix object\n",
        "m1 = data['train'].tocsr()\n",
        "\n",
        "print(m1[0,0])\n",
        "print(m1[0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7islioSWYdgn",
        "outputId": "627becfb-5c92-4791-9244-8d49486845fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t5\n",
            "  (0, 2)\t4\n",
            "  (0, 5)\t5\n",
            "  (0, 6)\t4\n",
            "  (0, 8)\t5\n",
            "  (0, 11)\t5\n",
            "  (0, 12)\t5\n",
            "  (0, 13)\t5\n",
            "  (0, 14)\t5\n",
            "  (0, 15)\t5\n",
            "  (0, 17)\t4\n",
            "  (0, 18)\t5\n",
            "  (0, 21)\t4\n",
            "  (0, 22)\t4\n",
            "  (0, 24)\t4\n",
            "  (0, 27)\t4\n",
            "  (0, 31)\t5\n",
            "  (0, 38)\t4\n",
            "  (0, 41)\t5\n",
            "  (0, 42)\t4\n",
            "  (0, 43)\t5\n",
            "  (0, 44)\t5\n",
            "  (0, 45)\t4\n",
            "  (0, 46)\t4\n",
            "  (0, 47)\t5\n",
            "  :\t:\n",
            "  (0, 223)\t5\n",
            "  (0, 226)\t4\n",
            "  (0, 227)\t5\n",
            "  (0, 228)\t4\n",
            "  (0, 229)\t4\n",
            "  (0, 233)\t4\n",
            "  (0, 234)\t5\n",
            "  (0, 235)\t4\n",
            "  (0, 237)\t4\n",
            "  (0, 238)\t4\n",
            "  (0, 240)\t4\n",
            "  (0, 241)\t5\n",
            "  (0, 245)\t5\n",
            "  (0, 247)\t4\n",
            "  (0, 248)\t4\n",
            "  (0, 249)\t4\n",
            "  (0, 250)\t4\n",
            "  (0, 252)\t5\n",
            "  (0, 255)\t4\n",
            "  (0, 256)\t4\n",
            "  (0, 257)\t5\n",
            "  (0, 266)\t4\n",
            "  (0, 267)\t5\n",
            "  (0, 268)\t5\n",
            "  (0, 269)\t5\n",
            "5\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcE4UE4Bytto"
      },
      "source": [
        "**coo_matrix - A sparse matrix in COOrdinate format - Intended Usage:**\n",
        "\n",
        "- COO is a fast format for constructing sparse matrices\n",
        "- Once a matrix has been constructed, convert to CSR or CSC format for fast arithmetic and matrix vector operations\n",
        "- By default when converting to CSR or CSC format, duplicate (i,j) entries will be summed together.  This facilitates efficient construction of finite element matrices and the like. (see example)\n",
        "<div>\n",
        "<img src=\"https://imgs.developpaper.com/imgs/10502062C-0.gif\" width=\"500\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(repr(data['train'])) # rept() is used in debugging to get a string representation of object\n",
        "print(repr(data['test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpBD1XpMY8EN",
        "outputId": "c3c5a39e-a56f-4ffb-fcaf-c9735b17ff23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 49906 stored elements in COOrdinate format>\n",
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 5469 stored elements in COOrdinate format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoGJfN120J5Q"
      },
      "source": [
        "# Let's now create and train our model\n",
        "\n",
        "**Four loss functions are available:**\n",
        "\n",
        "- **logistic**: useful when both positive (1) and negative (-1) interactions are present.\n",
        "- **BPR**: Bayesian Personalised Ranking pairwise loss. Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.\n",
        "- **WARP**: Weighted Approximate-Rank Pairwise loss. Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired.\n",
        "- **k-OS WARP**: k-th order statistic loss. A modification of WARP that uses the k-th positive example for any given user as a basis for pairwise updates.\n",
        "\n",
        "**Two learning rate schedules are available:**\n",
        "- adagrad\n",
        "- adadelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creat our model object from LightFM\n",
        "# We specify the loss type to be WARP (Weighted Approximate-Rank Pairwise )\n",
        "model = LightFM(loss = 'warp')"
      ],
      "metadata": {
        "id": "BW_aM3WoZiiU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract our training and test datasets\n",
        "train = data['train']\n",
        "test = data['test']"
      ],
      "metadata": {
        "id": "fm1nGVB7ZznL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit our model over 10 epochs\n",
        "model.fit(train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-9C1mtZ32F",
        "outputId": "40dafb9b-0f8d-4a60-dcde-a2e486954113"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f5658ad8f90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spfITtcp-By2"
      },
      "source": [
        "# Performance Evaluation\n",
        "\n",
        "We use Precision and AUC to avaluate our model performance.\n",
        "\n",
        "**The ROC AUC metric for a model**: the probability that a randomly chosen positive example has a higher score than a randomly chosen negative example.\n",
        "\n",
        "**The precision at k metric for a model**: the fraction of known positives in the first k positions of the ranked list of results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate it's performance\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.evaluation import auc_score\n",
        "\n",
        "train_precision = precision_at_k(model, train, k=10).mean()\n",
        "test_precision = precision_at_k(model, test, k=10).mean()\n",
        "\n",
        "train_auc = auc_score(model, train).mean()\n",
        "test_auc = auc_score(model, test).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
        "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Cf1Z3GZ7WJ",
        "outputId": "7630080e-0e09-4dcd-df18-f127273dd71a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.48, test 0.08.\n",
            "AUC: train 0.94, test 0.91.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRXeCHXG03GU"
      },
      "source": [
        "# Let's see what movies are recommended for some users"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function credit goes to Arun Mathew Kurian\n",
        "# Let's test it out and see how well it works \n",
        "# https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b\n",
        "def sample_recommendation(model, data, user_ids):\n",
        "    '''uses model, data and a list of users ideas and outputs the recommended movies along with known positives for each user'''\n",
        "    n_users, n_items = data['train'].shape\n",
        "    for user_id in user_ids:\n",
        "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
        "        \n",
        "        scores = model.predict(user_id, np.arange(n_items))\n",
        "\n",
        "        top_items = data['item_labels'][np.argsort(-scores)]\n",
        "      \n",
        "        print(\"User %s\" % user_id)\n",
        "        print(\"Known positives:\")\n",
        "        \n",
        "        # Print the first 3 known positives\n",
        "        for x in known_positives[:3]:\n",
        "            print(\"%s\" % x)\n",
        "        \n",
        "        # Print the first 3 recommended movies\n",
        "        print(\"Recommended:\")\n",
        "        for x in top_items[:3]:\n",
        "            print(\"%s\" % x)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "y9clvVAJaLpC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on users: 6, 125 and 336\n",
        "sample_recommendation(model, data, [6, 125, 336])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd5vDkcmaU_c",
        "outputId": "3c505db0-4f04-488d-ec98-86de95d33c01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 6\n",
            "Known positives:\n",
            "Get Shorty (1995)\n",
            "Twelve Monkeys (1995)\n",
            "Babe (1995)\n",
            "Recommended:\n",
            "Raiders of the Lost Ark (1981)\n",
            "Blade Runner (1982)\n",
            "Empire Strikes Back, The (1980)\n",
            "\n",
            "\n",
            "User 125\n",
            "Known positives:\n",
            "Jungle2Jungle (1997)\n",
            "Kull the Conqueror (1997)\n",
            "Scream (1996)\n",
            "Recommended:\n",
            "L.A. Confidential (1997)\n",
            "Scream (1996)\n",
            "Seven Years in Tibet (1997)\n",
            "\n",
            "\n",
            "User 336\n",
            "Known positives:\n",
            "Mr. Holland's Opus (1995)\n",
            "Star Wars (1977)\n",
            "Ace Ventura: Pet Detective (1994)\n",
            "Recommended:\n",
            "Return of the Jedi (1983)\n",
            "Star Wars (1977)\n",
            "Independence Day (ID4) (1996)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpao0Fmi0TcX"
      },
      "source": [
        "### Learn to build and create your own datasets for LightFM here\n",
        "\n",
        "https://lyst.github.io/lightfm/docs/examples/dataset.html"
      ]
    }
  ]
}